<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-giJF6kkoqNQ00vy+HMDP7azOuL0xtbfIcaT9wjKHr8RbDVddVHyTfAAsrekwKmP1" crossorigin="anonymous">
    <title>Randomized Priors vs Stochastic Weight Averaging Gaussian Demo</title>
</head>
<body>
<div class="container" id="canvasContainer">
    <div class="row">
        <div class="col-4 justify-content-end">
            <canvas id="myCanvas" width="400" height="400"
                    style="background-color: black; border:1px solid #000000;"></canvas>
        </div>
        <div class="col-8 justify-content-start" id="chart" style="float: left;"></div>
    </div>
    <div class="row">
        <div class="col-4 justify-content-end">
            <div>
                <button class="btn btn-primary" id="clearBtn" style="margin: 10px 10px 10px 10px;">Clear</button>
            </div>
        </div>
        <div class="col-8 justify-content-start">
            <div>
                <div>Last input:
                    <iframe
                            width=40
                            height=40
                            id="lastInput"
                            src=""
                            title="Last Input"
                            style="overflow: hidden;"
                            scrolling="no"
                    ></iframe>
                </div>
                <p>Last prediction (Standard Classifier): <span id="lastPredStandardClassifier"></span></p>
                <p>Last prediction (Randomized Priors): <span id="lastPredRandomizedPriors"></span></p>
                <p>Last prediction (SWA-Gaussian): <span id="lastPredSWAG"></span></p>

            </div>
        </div>
    </div>
	<div class="row">
		<p> This project is a comparison of different methods used to generate an approximation to the predictive posterior
		distribution of a neural networks. A standard, basic classifier was trained on MNIST data and achieved an
		accuracy of 95.8%. The structure of the network is visible
		<a href=https://netron.app?url=https://jgibson2.github.io/posterior_comparison/models/standard_classifier.onnx>here</a>.
		Then, techniques from the papers <a href=https://arxiv.org/abs/1902.02476>A Simple Baseline for Bayesian Uncertainty in Deep Learning</a>
		(e.g. SWA-Gaussian) and <a href=https://arxiv.org/abs/1806.03335>Randomized Prior Functions for Deep Reinforcement Learning</a> were implemented
		in PyTorch and exported to ONNX by drawing 20 networks from the "posterior" and taking the average over the outputs. The implementations are available
		<a href=https://github.com/jgibson2/pytorch-experiments>here</a>, and the network structures are explorable for
		<a href=https://netron.app?url=https://jgibson2.github.io/posterior_comparison/models/combined_classifier_randomized_priors.onnx>Randomized Priors</a>
		and <a href=https://netron.app?url=https://jgibson2.github.io/posterior_comparison/models/combined_classifier_swa_gaussian.onnx>SWA-Gaussian</a>
		using Netron. On the SWA-Gaussian and Randomized Priors outputs, error bars are added which correspond to the standard deviation
        of the prediction outputs from the 20 models that make up the classifier. This allows us to see how confident the networks are
        in their predictions.
        To use the demo, use your mouse to draw a digit in the box and see how the different techniques behave, especially when given digits
		that are not clearly of one class. </p>
	</div>
</div>
<script src="js/jquery-3.5.1.min.js"></script>
<script src="js/paper-core.js"></script>
<script src="js/ndarray-browser-min.js"></script>
<script src="js/onnx.min.js"></script>
<script src="https://cdn.plot.ly/plotly-latest.min.js" charset="utf-8"></script>
<script src="js/comparison.js"></script>
</body>

</html>